{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "## Preliminaries\n",
    "### Introduction\n",
    "For the best performance for an ML-Model, we need to find the best hyperparameters. This file is for finding those. We want to evaluate\n",
    "* Number of Neurons in each layer (for 20 Epochs, learning rate of 0.001 and lag of 60: best at 800)\n",
    "* Number of epochs/Batch_Size\n",
    "* learning rate\n",
    "* lag\n",
    "\n",
    "For each of these parameters, we conduct an experiment of 50 values within chosen boundaries while all other parameters stay the same. For each of the parameters we safe the top 3 parameters and conduct a cross analysis out of those which combination works best.\n",
    "\n",
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# homemade libraries\n",
    "import Global_Functions as gf\n",
    "import Neuronal_Networks as nn\n",
    "import Data_Processing as dp\n",
    "\n",
    "# Processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "\n",
    "import time\n",
    "timestr = time.strftime(\"%Y-%m-%d_%H-%M/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_FOLDER = '../Data/Preped_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_1 = gf.open_CSV_file('experiment_1_short.csv', OPEN_FOLDER)\n",
    "ex_4 = gf.open_CSV_file('experiment_4_short.csv', OPEN_FOLDER)\n",
    "ex_9 = gf.open_CSV_file('experiment_9_short.csv', OPEN_FOLDER)\n",
    "ex_20 = gf.open_CSV_file('experiment_20_short.csv', OPEN_FOLDER)\n",
    "ex_21 = gf.open_CSV_file('experiment_21_short.csv', OPEN_FOLDER)\n",
    "ex_22 = gf.open_CSV_file('experiment_22_short.csv', OPEN_FOLDER)\n",
    "ex_23 = gf.open_CSV_file('experiment_23_short.csv', OPEN_FOLDER)\n",
    "ex_24 = gf.open_CSV_file('experiment_24_short.csv', OPEN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [ex_1, ex_4, ex_9, ex_20, ex_21, ex_22, ex_23, ex_24]\n",
    "names = ['1', '4', '9', '20', '21','22', '23', '24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"20\"\n",
    "val = \"21\"\n",
    "test = \"22\"\n",
    "\n",
    "ex_train = ex_20\n",
    "ex_val = ex_21\n",
    "ex_test = ex_22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify default parameters\n",
    "Once again keep in mind, we change one of those parameters in every run through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEURONS = 128       #sensible boundaries are [8, 1024]\n",
    "EPOCHS = 500        #sensible boundaries are [10,500]\n",
    "LAG = 60            #sensible boundaries are [1,1000]\n",
    "LEARNING_RATE = 0.001 #sensible boundaries are [0.001, 1]\n",
    "BATCH_SIZE = 512    #sensible boundaries are [1, 1024]\n",
    "ITERATIONS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of directory ../Images/Hyperparameter_Optimization/2021-05-27_14-39/ successful.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"../Images/Hyperparameter_Optimization/\" + timestr\n",
    "image_subfolder = image_path\n",
    "gf.check_folder(image_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, lag = 1, all_inputs = True, include_power = False):\n",
    "    length = len(data)\n",
    "    input_scaled, scaler_input = dp.scale(data['input_voltage'])\n",
    "    power_scaled, scaler_power = dp.scale(data['el_power'])\n",
    "    \n",
    "    scaler = [scaler_input, scaler_power]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(lag):\n",
    "        df['input_voltage_delay_' + str(i)] = np.roll(input_scaled, i)[:length]\n",
    "        df['el_power_delay_' + str(i)] = np.roll(power_scaled, i)[:length]\n",
    "        \n",
    "    # use either all lags or only the immediate input and the voltages just before.\n",
    "    if all_inputs:\n",
    "        filter_cols = [col for col in df if col.startswith('input_voltage_delay')]\n",
    "        X = df[filter_cols]\n",
    "    else:\n",
    "        X = df[['input_voltage_delay_0', 'input_voltage_delay_' + str(lag-1)]]\n",
    "    \n",
    "    if include_power:\n",
    "        X['el_power_delay_' + str(lag -1)] = df['el_power_delay_' + str(lag-1)]\n",
    "        \n",
    "    df['differences'] = df['el_power_delay_' + str(lag -1)] - df['el_power_delay_0']\n",
    "    differences_scaled, scaler_differences = dp.scale(df['differences'])\n",
    "    df['differences'] = differences_scaled\n",
    "    scaler.append(scaler_differences)\n",
    "    \n",
    "    y = df[['el_power_delay_0', 'differences']]\n",
    "    \n",
    "    X = X.values\n",
    "    X = X.reshape(X.shape[0],1 , X.shape[1])\n",
    "    \n",
    "    y = y.values\n",
    "    y = y.reshape(y.shape[0], 1, y.shape[1])\n",
    "    \n",
    "    return scaler, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "    # Plot the loss function\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "    ax.plot(np.sqrt(history.history['loss']), 'r', label='train')\n",
    "    ax.plot(np.sqrt(history.history['val_loss']), 'b' ,label='val')\n",
    "    ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "    ax.set_ylabel(r'Loss', fontsize=20)\n",
    "    ax.legend()\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "    # Plot the accuracy\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "    ax.plot(np.sqrt(history.history['accuracy']), 'r', label='train')\n",
    "    ax.plot(np.sqrt(history.history['val_accuracy']), 'b' ,label='val')\n",
    "    ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "    ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "    ax.legend()\n",
    "    ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(experiment, model, image_fol, batch_size = 1, specs = \"\"):\n",
    "    scaler, X, y = prepare_data(experiment, lag = LAG)\n",
    "    \n",
    "    preds_scaled = model.predict(X, batch_size = batch_size)\n",
    "    preds = scaler[1].inverse_transform(preds_scaled)[:,0]\n",
    "    preds_diff = scaler[1].inverse_transform(scaler[2].inverse_transform(preds_scaled)[:,1])\n",
    "    true = scaler[1].inverse_transform(y[:,0])\n",
    "    \n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    plt.plot(true[:,0], color = gf.get_color(\"grey\"), label = \"True\")\n",
    "    plt.plot(preds, color = gf.get_color(\"green\"), label = \"Predictions\")\n",
    "    plt.ylabel('Electric power [W]', fontsize = 18)\n",
    "    plt.xlabel('Time [sec]', fontsize = 18)\n",
    "    plt.legend()\n",
    "    plt.title('Predictions using loss function ' + specs, fontsize = 25)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(image_fol + specs + \"predictions.png\")\n",
    "    fig.savefig(image_fol + specs + \"predictions.svg\")\n",
    "    \n",
    "    fig.clear()\n",
    "    \n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    plt.plot(true[:,1], color = gf.get_color(\"grey\"), label = \"True\")\n",
    "    plt.plot(preds_diff, color = gf.get_color(\"green\"), label = \"Predictions\")\n",
    "    plt.ylabel('Difference in Electric power [W]', fontsize = 18)\n",
    "    plt.xlabel('Time [sec]', fontsize = 18)\n",
    "    plt.legend()\n",
    "    plt.title('Predictions of Differences using loss function ' + specs, fontsize = 25)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(image_fol + specs + \"preds_differences.png\")\n",
    "    fig.savefig(image_fol + specs + \"preds_differences.svg\")\n",
    "    \n",
    "    return scaler, X, y, preds_scaled, preds, preds_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, image_fol):\n",
    "    investigate_experiments = [ex_train, ex_val, ex_test]\n",
    "    investigate_names = ['train', 'val', 'test']\n",
    "    for i in range(len(investigate_experiments)):\n",
    "        predictions(investigate_experiments[i], model, image_fol, specs = \"on {0} data\".format(investigate_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal hyperparameters\n",
    "\n",
    "### Neurons\n",
    "We start with the number of neurons in each layer. Note, that this number only holds for the first value since the second layer is only half of the neurons. The output layer only contains two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of directory ../Images/Hyperparameter_Optimization/2021-05-27_14-39/BATCH_SIZE/ successful.\n"
     ]
    }
   ],
   "source": [
    "image_folder = image_subfolder + \"BATCH_SIZE/\"\n",
    "gf.check_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_batch_sizes = []\n",
    "# for i in range(40):\n",
    "#     possible_batch_sizes.append(random.randint(16, 1024))\n",
    "for i in range(12):\n",
    "    possible_batch_sizes.append(int(2**(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_models(top = 3):\n",
    "    all_models = list()\n",
    "    all_histories = list()\n",
    "    all_accs = list()\n",
    "    all_accs_val = list()\n",
    "    all_losses = list()\n",
    "    all_losses_val = list()\n",
    "    \n",
    "    scaler_train, X_train, y_train = dp.prepare_data(ex_train, lag = LAG)\n",
    "    scaler_val, X_val, y_val = dp.prepare_data(ex_val, lag = LAG)\n",
    "\n",
    "    for b in possible_batch_sizes:\n",
    "        batches_per_run = int(len(X_train)//b)\n",
    "        EPOCHS = int(ITERATIONS//batches_per_run)\n",
    "        model, history = nn.fit_lstm(X_train, y_train, X_val, y_val, batch_size = b,\n",
    "                                     nb_epochs = EPOCHS, neurons = NEURONS)\n",
    "        model.save(\"../Model/Hyper_parameter/BATCH_SIZE/\" + str(b) +\"/model.h5\")\n",
    "        \n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        for i in history:\n",
    "            losses.append(i.history['loss'])\n",
    "            val_losses.append(i.history['val_loss'])\n",
    "        all_models.append(model)\n",
    "        all_histories.append(history)\n",
    "        all_losses.append(losses[0])\n",
    "        all_losses_val.append(val_losses[0])\n",
    "        \n",
    "    all_losses_val = [config_loss[0] for config_loss in all_losses_val]\n",
    "    models_losses_val_sorted = all_losses_val.copy()\n",
    "    models_losses_val_sorted.sort(reverse=True)\n",
    "    top_losses = models_losses_val_sorted[:top]\n",
    "    top_models = list()\n",
    "    top_histories = list()\n",
    "    indices = list()\n",
    "    for rank in top_losses:\n",
    "        index = all_losses_val.index(rank)\n",
    "        top_models.append(all_models[index])\n",
    "        top_histories.append(all_histories[index])\n",
    "        indices.append(index)\n",
    "    return top_models, top_histories, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysze_top3(history):\n",
    "    for h in history:\n",
    "        plot_performance(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 12 is done.\n",
      "Epoch 10 of 24 is done.\n",
      "Epoch 20 of 24 is done.\n",
      "Epoch 10 of 49 is done.\n",
      "Epoch 20 of 49 is done.\n",
      "Epoch 30 of 49 is done.\n",
      "Epoch 40 of 49 is done.\n",
      "Epoch 10 of 99 is done.\n",
      "Epoch 20 of 99 is done.\n",
      "Epoch 30 of 99 is done.\n",
      "Epoch 40 of 99 is done.\n",
      "Epoch 50 of 99 is done.\n",
      "Epoch 60 of 99 is done.\n",
      "Epoch 70 of 99 is done.\n",
      "Epoch 80 of 99 is done.\n",
      "Epoch 90 of 99 is done.\n",
      "Epoch 10 of 200 is done.\n",
      "Epoch 20 of 200 is done.\n",
      "Epoch 30 of 200 is done.\n",
      "Epoch 40 of 200 is done.\n",
      "Epoch 50 of 200 is done.\n",
      "Epoch 60 of 200 is done.\n",
      "Epoch 70 of 200 is done.\n",
      "Epoch 80 of 200 is done.\n",
      "Epoch 90 of 200 is done.\n",
      "Epoch 100 of 200 is done.\n",
      "Epoch 110 of 200 is done.\n",
      "Epoch 120 of 200 is done.\n",
      "Epoch 130 of 200 is done.\n",
      "Epoch 140 of 200 is done.\n",
      "Epoch 150 of 200 is done.\n",
      "Epoch 160 of 200 is done.\n",
      "Epoch 170 of 200 is done.\n",
      "Epoch 180 of 200 is done.\n",
      "Epoch 190 of 200 is done.\n",
      "Epoch 200 of 200 is done.\n",
      "Epoch 10 of 400 is done.\n",
      "Epoch 20 of 400 is done.\n",
      "Epoch 30 of 400 is done.\n",
      "Epoch 40 of 400 is done.\n",
      "Epoch 50 of 400 is done.\n",
      "Epoch 60 of 400 is done.\n",
      "Epoch 70 of 400 is done.\n",
      "Epoch 80 of 400 is done.\n",
      "Epoch 90 of 400 is done.\n",
      "Epoch 100 of 400 is done.\n",
      "Epoch 110 of 400 is done.\n",
      "Epoch 120 of 400 is done.\n",
      "Epoch 130 of 400 is done.\n",
      "Epoch 140 of 400 is done.\n",
      "Epoch 150 of 400 is done.\n",
      "Epoch 160 of 400 is done.\n",
      "Epoch 170 of 400 is done.\n",
      "Epoch 180 of 400 is done.\n",
      "Epoch 190 of 400 is done.\n",
      "Epoch 200 of 400 is done.\n",
      "Epoch 210 of 400 is done.\n",
      "Epoch 220 of 400 is done.\n",
      "Epoch 230 of 400 is done.\n",
      "Epoch 240 of 400 is done.\n",
      "Epoch 250 of 400 is done.\n",
      "Epoch 260 of 400 is done.\n",
      "Epoch 270 of 400 is done.\n",
      "Epoch 280 of 400 is done.\n",
      "Epoch 290 of 400 is done.\n",
      "Epoch 300 of 400 is done.\n",
      "Epoch 310 of 400 is done.\n",
      "Epoch 320 of 400 is done.\n",
      "Epoch 330 of 400 is done.\n",
      "Epoch 340 of 400 is done.\n",
      "Epoch 350 of 400 is done.\n",
      "Epoch 360 of 400 is done.\n",
      "Epoch 370 of 400 is done.\n",
      "Epoch 380 of 400 is done.\n",
      "Epoch 390 of 400 is done.\n",
      "Epoch 400 of 400 is done.\n",
      "Epoch 10 of 833 is done.\n",
      "Epoch 20 of 833 is done.\n",
      "Epoch 30 of 833 is done.\n",
      "Epoch 40 of 833 is done.\n",
      "Epoch 50 of 833 is done.\n",
      "Epoch 60 of 833 is done.\n",
      "Epoch 70 of 833 is done.\n",
      "Epoch 80 of 833 is done.\n",
      "Epoch 90 of 833 is done.\n",
      "Epoch 100 of 833 is done.\n",
      "Epoch 110 of 833 is done.\n",
      "Epoch 120 of 833 is done.\n",
      "Epoch 130 of 833 is done.\n",
      "Epoch 140 of 833 is done.\n",
      "Epoch 150 of 833 is done.\n",
      "Epoch 160 of 833 is done.\n",
      "Epoch 170 of 833 is done.\n",
      "Epoch 180 of 833 is done.\n",
      "Epoch 190 of 833 is done.\n",
      "Epoch 200 of 833 is done.\n",
      "Epoch 210 of 833 is done.\n",
      "Epoch 220 of 833 is done.\n",
      "Epoch 230 of 833 is done.\n",
      "Epoch 240 of 833 is done.\n",
      "Epoch 250 of 833 is done.\n",
      "Epoch 260 of 833 is done.\n",
      "Epoch 270 of 833 is done.\n",
      "Epoch 280 of 833 is done.\n",
      "Epoch 290 of 833 is done.\n",
      "Epoch 300 of 833 is done.\n",
      "Epoch 310 of 833 is done.\n",
      "Epoch 320 of 833 is done.\n",
      "Epoch 330 of 833 is done.\n",
      "Epoch 340 of 833 is done.\n",
      "Epoch 350 of 833 is done.\n",
      "Epoch 360 of 833 is done.\n",
      "Epoch 370 of 833 is done.\n",
      "Epoch 380 of 833 is done.\n",
      "Epoch 390 of 833 is done.\n",
      "Epoch 400 of 833 is done.\n",
      "Epoch 410 of 833 is done.\n",
      "Epoch 420 of 833 is done.\n",
      "Epoch 430 of 833 is done.\n",
      "Epoch 440 of 833 is done.\n",
      "Epoch 450 of 833 is done.\n",
      "Epoch 460 of 833 is done.\n",
      "Epoch 470 of 833 is done.\n",
      "Epoch 480 of 833 is done.\n",
      "Epoch 490 of 833 is done.\n",
      "Epoch 500 of 833 is done.\n",
      "Epoch 510 of 833 is done.\n",
      "Epoch 520 of 833 is done.\n",
      "Epoch 530 of 833 is done.\n",
      "Epoch 540 of 833 is done.\n",
      "Epoch 550 of 833 is done.\n",
      "Epoch 560 of 833 is done.\n",
      "Epoch 570 of 833 is done.\n",
      "Epoch 580 of 833 is done.\n",
      "Epoch 590 of 833 is done.\n",
      "Epoch 600 of 833 is done.\n",
      "Epoch 610 of 833 is done.\n",
      "Epoch 620 of 833 is done.\n",
      "Epoch 630 of 833 is done.\n",
      "Epoch 640 of 833 is done.\n",
      "Epoch 650 of 833 is done.\n",
      "Epoch 660 of 833 is done.\n",
      "Epoch 670 of 833 is done.\n",
      "Epoch 680 of 833 is done.\n",
      "Epoch 690 of 833 is done.\n",
      "Epoch 700 of 833 is done.\n",
      "Epoch 710 of 833 is done.\n",
      "Epoch 720 of 833 is done.\n",
      "Epoch 730 of 833 is done.\n",
      "Epoch 740 of 833 is done.\n",
      "Epoch 750 of 833 is done.\n",
      "Epoch 760 of 833 is done.\n",
      "Epoch 770 of 833 is done.\n",
      "Epoch 780 of 833 is done.\n",
      "Epoch 790 of 833 is done.\n",
      "Epoch 800 of 833 is done.\n",
      "Epoch 810 of 833 is done.\n",
      "Epoch 820 of 833 is done.\n",
      "Epoch 830 of 833 is done.\n",
      "Epoch 10 of 1666 is done.\n",
      "Epoch 20 of 1666 is done.\n",
      "Epoch 30 of 1666 is done.\n",
      "Epoch 40 of 1666 is done.\n",
      "Epoch 50 of 1666 is done.\n",
      "Epoch 60 of 1666 is done.\n",
      "Epoch 70 of 1666 is done.\n",
      "Epoch 80 of 1666 is done.\n",
      "Epoch 90 of 1666 is done.\n",
      "Epoch 100 of 1666 is done.\n",
      "Epoch 110 of 1666 is done.\n",
      "Epoch 120 of 1666 is done.\n",
      "Epoch 130 of 1666 is done.\n",
      "Epoch 140 of 1666 is done.\n",
      "Epoch 150 of 1666 is done.\n",
      "Epoch 160 of 1666 is done.\n",
      "Epoch 170 of 1666 is done.\n",
      "Epoch 180 of 1666 is done.\n",
      "Epoch 190 of 1666 is done.\n",
      "Epoch 200 of 1666 is done.\n",
      "Epoch 210 of 1666 is done.\n",
      "Epoch 220 of 1666 is done.\n",
      "Epoch 230 of 1666 is done.\n",
      "Epoch 240 of 1666 is done.\n",
      "Epoch 250 of 1666 is done.\n",
      "Epoch 260 of 1666 is done.\n",
      "Epoch 270 of 1666 is done.\n",
      "Epoch 280 of 1666 is done.\n",
      "Epoch 290 of 1666 is done.\n",
      "Epoch 300 of 1666 is done.\n",
      "Epoch 310 of 1666 is done.\n",
      "Epoch 320 of 1666 is done.\n",
      "Epoch 330 of 1666 is done.\n",
      "Epoch 340 of 1666 is done.\n",
      "Epoch 350 of 1666 is done.\n",
      "Epoch 360 of 1666 is done.\n",
      "Epoch 370 of 1666 is done.\n",
      "Epoch 380 of 1666 is done.\n",
      "Epoch 390 of 1666 is done.\n",
      "Epoch 400 of 1666 is done.\n",
      "Epoch 410 of 1666 is done.\n",
      "Epoch 420 of 1666 is done.\n",
      "Epoch 430 of 1666 is done.\n",
      "Epoch 440 of 1666 is done.\n",
      "Epoch 450 of 1666 is done.\n",
      "Epoch 460 of 1666 is done.\n",
      "Epoch 470 of 1666 is done.\n",
      "Epoch 480 of 1666 is done.\n",
      "Epoch 490 of 1666 is done.\n",
      "Epoch 500 of 1666 is done.\n",
      "Epoch 510 of 1666 is done.\n",
      "Epoch 520 of 1666 is done.\n",
      "Epoch 530 of 1666 is done.\n",
      "Epoch 540 of 1666 is done.\n",
      "Epoch 550 of 1666 is done.\n",
      "Epoch 560 of 1666 is done.\n",
      "Epoch 570 of 1666 is done.\n",
      "Epoch 580 of 1666 is done.\n",
      "Epoch 590 of 1666 is done.\n",
      "Epoch 600 of 1666 is done.\n",
      "Epoch 610 of 1666 is done.\n",
      "Epoch 620 of 1666 is done.\n",
      "Epoch 630 of 1666 is done.\n",
      "Epoch 640 of 1666 is done.\n",
      "Epoch 650 of 1666 is done.\n",
      "Epoch 660 of 1666 is done.\n",
      "Epoch 670 of 1666 is done.\n",
      "Epoch 680 of 1666 is done.\n",
      "Epoch 690 of 1666 is done.\n",
      "Epoch 700 of 1666 is done.\n",
      "Epoch 710 of 1666 is done.\n",
      "Epoch 720 of 1666 is done.\n",
      "Epoch 730 of 1666 is done.\n",
      "Epoch 740 of 1666 is done.\n",
      "Epoch 750 of 1666 is done.\n",
      "Epoch 760 of 1666 is done.\n",
      "Epoch 770 of 1666 is done.\n",
      "Epoch 780 of 1666 is done.\n",
      "Epoch 790 of 1666 is done.\n",
      "Epoch 800 of 1666 is done.\n",
      "Epoch 810 of 1666 is done.\n",
      "Epoch 820 of 1666 is done.\n",
      "Epoch 830 of 1666 is done.\n",
      "Epoch 840 of 1666 is done.\n",
      "Epoch 850 of 1666 is done.\n",
      "Epoch 860 of 1666 is done.\n",
      "Epoch 870 of 1666 is done.\n",
      "Epoch 880 of 1666 is done.\n",
      "Epoch 890 of 1666 is done.\n",
      "Epoch 900 of 1666 is done.\n",
      "Epoch 910 of 1666 is done.\n",
      "Epoch 920 of 1666 is done.\n",
      "Epoch 930 of 1666 is done.\n",
      "Epoch 940 of 1666 is done.\n",
      "Epoch 950 of 1666 is done.\n",
      "Epoch 960 of 1666 is done.\n",
      "Epoch 970 of 1666 is done.\n",
      "Epoch 980 of 1666 is done.\n",
      "Epoch 990 of 1666 is done.\n",
      "Epoch 1000 of 1666 is done.\n",
      "Epoch 1010 of 1666 is done.\n",
      "Epoch 1020 of 1666 is done.\n",
      "Epoch 1030 of 1666 is done.\n",
      "Epoch 1040 of 1666 is done.\n",
      "Epoch 1050 of 1666 is done.\n",
      "Epoch 1060 of 1666 is done.\n",
      "Epoch 1070 of 1666 is done.\n",
      "Epoch 1080 of 1666 is done.\n",
      "Epoch 1090 of 1666 is done.\n",
      "Epoch 1100 of 1666 is done.\n",
      "Epoch 1110 of 1666 is done.\n",
      "Epoch 1120 of 1666 is done.\n",
      "Epoch 1130 of 1666 is done.\n",
      "Epoch 1140 of 1666 is done.\n",
      "Epoch 1150 of 1666 is done.\n",
      "Epoch 1160 of 1666 is done.\n",
      "Epoch 1170 of 1666 is done.\n",
      "Epoch 1180 of 1666 is done.\n",
      "Epoch 1190 of 1666 is done.\n",
      "Epoch 1200 of 1666 is done.\n",
      "Epoch 1210 of 1666 is done.\n",
      "Epoch 1220 of 1666 is done.\n",
      "Epoch 1230 of 1666 is done.\n",
      "Epoch 1240 of 1666 is done.\n",
      "Epoch 1250 of 1666 is done.\n",
      "Epoch 1260 of 1666 is done.\n",
      "Epoch 1270 of 1666 is done.\n",
      "Epoch 1280 of 1666 is done.\n",
      "Epoch 1290 of 1666 is done.\n",
      "Epoch 1300 of 1666 is done.\n",
      "Epoch 1310 of 1666 is done.\n",
      "Epoch 1320 of 1666 is done.\n",
      "Epoch 1330 of 1666 is done.\n",
      "Epoch 1340 of 1666 is done.\n",
      "Epoch 1350 of 1666 is done.\n",
      "Epoch 1360 of 1666 is done.\n",
      "Epoch 1370 of 1666 is done.\n",
      "Epoch 1380 of 1666 is done.\n",
      "Epoch 1390 of 1666 is done.\n",
      "Epoch 1400 of 1666 is done.\n",
      "Epoch 1410 of 1666 is done.\n",
      "Epoch 1420 of 1666 is done.\n",
      "Epoch 1430 of 1666 is done.\n",
      "Epoch 1440 of 1666 is done.\n",
      "Epoch 1450 of 1666 is done.\n",
      "Epoch 1460 of 1666 is done.\n",
      "Epoch 1470 of 1666 is done.\n",
      "Epoch 1480 of 1666 is done.\n",
      "Epoch 1490 of 1666 is done.\n",
      "Epoch 1500 of 1666 is done.\n",
      "Epoch 1510 of 1666 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1520 of 1666 is done.\n",
      "Epoch 1530 of 1666 is done.\n",
      "Epoch 1540 of 1666 is done.\n",
      "Epoch 1550 of 1666 is done.\n",
      "Epoch 1560 of 1666 is done.\n",
      "Epoch 1570 of 1666 is done.\n",
      "Epoch 1580 of 1666 is done.\n",
      "Epoch 1590 of 1666 is done.\n",
      "Epoch 1600 of 1666 is done.\n",
      "Epoch 1610 of 1666 is done.\n",
      "Epoch 1620 of 1666 is done.\n",
      "Epoch 1630 of 1666 is done.\n",
      "Epoch 1640 of 1666 is done.\n",
      "Epoch 1650 of 1666 is done.\n",
      "Epoch 1660 of 1666 is done.\n",
      "Epoch 10 of 3333 is done.\n",
      "Epoch 20 of 3333 is done.\n",
      "Epoch 30 of 3333 is done.\n",
      "Epoch 40 of 3333 is done.\n",
      "Epoch 50 of 3333 is done.\n",
      "Epoch 60 of 3333 is done.\n",
      "Epoch 70 of 3333 is done.\n",
      "Epoch 80 of 3333 is done.\n",
      "Epoch 90 of 3333 is done.\n",
      "Epoch 100 of 3333 is done.\n",
      "Epoch 110 of 3333 is done.\n",
      "Epoch 120 of 3333 is done.\n",
      "Epoch 130 of 3333 is done.\n",
      "Epoch 140 of 3333 is done.\n",
      "Epoch 150 of 3333 is done.\n",
      "Epoch 160 of 3333 is done.\n",
      "Epoch 170 of 3333 is done.\n",
      "Epoch 180 of 3333 is done.\n",
      "Epoch 190 of 3333 is done.\n",
      "Epoch 200 of 3333 is done.\n",
      "Epoch 210 of 3333 is done.\n",
      "Epoch 220 of 3333 is done.\n",
      "Epoch 230 of 3333 is done.\n",
      "Epoch 240 of 3333 is done.\n",
      "Epoch 250 of 3333 is done.\n",
      "Epoch 260 of 3333 is done.\n",
      "Epoch 270 of 3333 is done.\n",
      "Epoch 280 of 3333 is done.\n",
      "Epoch 290 of 3333 is done.\n",
      "Epoch 300 of 3333 is done.\n",
      "Epoch 310 of 3333 is done.\n",
      "Epoch 320 of 3333 is done.\n",
      "Epoch 330 of 3333 is done.\n",
      "Epoch 340 of 3333 is done.\n",
      "Epoch 350 of 3333 is done.\n",
      "Epoch 360 of 3333 is done.\n",
      "Epoch 370 of 3333 is done.\n",
      "Epoch 380 of 3333 is done.\n",
      "Epoch 390 of 3333 is done.\n",
      "Epoch 400 of 3333 is done.\n",
      "Epoch 410 of 3333 is done.\n",
      "Epoch 420 of 3333 is done.\n",
      "Epoch 430 of 3333 is done.\n",
      "Epoch 440 of 3333 is done.\n",
      "Epoch 450 of 3333 is done.\n",
      "Epoch 460 of 3333 is done.\n",
      "Epoch 470 of 3333 is done.\n",
      "Epoch 480 of 3333 is done.\n",
      "Epoch 490 of 3333 is done.\n",
      "Epoch 500 of 3333 is done.\n",
      "Epoch 510 of 3333 is done.\n",
      "Epoch 520 of 3333 is done.\n",
      "Epoch 530 of 3333 is done.\n",
      "Epoch 540 of 3333 is done.\n",
      "Epoch 550 of 3333 is done.\n",
      "Epoch 560 of 3333 is done.\n",
      "Epoch 570 of 3333 is done.\n",
      "Epoch 580 of 3333 is done.\n",
      "Epoch 590 of 3333 is done.\n",
      "Epoch 600 of 3333 is done.\n",
      "Epoch 610 of 3333 is done.\n",
      "Epoch 620 of 3333 is done.\n",
      "Epoch 630 of 3333 is done.\n",
      "Epoch 640 of 3333 is done.\n",
      "Epoch 650 of 3333 is done.\n",
      "Epoch 660 of 3333 is done.\n",
      "Epoch 670 of 3333 is done.\n",
      "Epoch 680 of 3333 is done.\n",
      "Epoch 690 of 3333 is done.\n",
      "Epoch 700 of 3333 is done.\n",
      "Epoch 710 of 3333 is done.\n",
      "Epoch 720 of 3333 is done.\n",
      "Epoch 730 of 3333 is done.\n",
      "Epoch 740 of 3333 is done.\n",
      "Epoch 750 of 3333 is done.\n",
      "Epoch 760 of 3333 is done.\n",
      "Epoch 770 of 3333 is done.\n",
      "Epoch 780 of 3333 is done.\n",
      "Epoch 790 of 3333 is done.\n",
      "Epoch 800 of 3333 is done.\n",
      "Epoch 810 of 3333 is done.\n",
      "Epoch 820 of 3333 is done.\n",
      "Epoch 830 of 3333 is done.\n",
      "Epoch 840 of 3333 is done.\n",
      "Epoch 850 of 3333 is done.\n",
      "Epoch 860 of 3333 is done.\n",
      "Epoch 870 of 3333 is done.\n",
      "Epoch 880 of 3333 is done.\n",
      "Epoch 890 of 3333 is done.\n",
      "Epoch 900 of 3333 is done.\n",
      "Epoch 910 of 3333 is done.\n",
      "Epoch 920 of 3333 is done.\n",
      "Epoch 930 of 3333 is done.\n",
      "Epoch 940 of 3333 is done.\n",
      "Epoch 950 of 3333 is done.\n",
      "Epoch 960 of 3333 is done.\n",
      "Epoch 970 of 3333 is done.\n",
      "Epoch 980 of 3333 is done.\n",
      "Epoch 990 of 3333 is done.\n",
      "Epoch 1000 of 3333 is done.\n",
      "Epoch 1010 of 3333 is done.\n",
      "Epoch 1020 of 3333 is done.\n",
      "Epoch 1030 of 3333 is done.\n",
      "Epoch 1040 of 3333 is done.\n",
      "Epoch 1050 of 3333 is done.\n",
      "Epoch 1060 of 3333 is done.\n",
      "Epoch 1070 of 3333 is done.\n",
      "Epoch 1080 of 3333 is done.\n",
      "Epoch 1090 of 3333 is done.\n",
      "Epoch 1100 of 3333 is done.\n",
      "Epoch 1110 of 3333 is done.\n",
      "Epoch 1120 of 3333 is done.\n",
      "Epoch 1130 of 3333 is done.\n",
      "Epoch 1140 of 3333 is done.\n",
      "Epoch 1150 of 3333 is done.\n",
      "Epoch 1160 of 3333 is done.\n",
      "Epoch 1170 of 3333 is done.\n",
      "Epoch 1180 of 3333 is done.\n",
      "Epoch 1190 of 3333 is done.\n",
      "Epoch 1200 of 3333 is done.\n",
      "Epoch 1210 of 3333 is done.\n",
      "Epoch 1220 of 3333 is done.\n",
      "Epoch 1230 of 3333 is done.\n",
      "Epoch 1240 of 3333 is done.\n",
      "Epoch 1250 of 3333 is done.\n",
      "Epoch 1260 of 3333 is done.\n",
      "Epoch 1270 of 3333 is done.\n",
      "Epoch 1280 of 3333 is done.\n",
      "Epoch 1290 of 3333 is done.\n",
      "Epoch 1300 of 3333 is done.\n",
      "Epoch 1310 of 3333 is done.\n",
      "Epoch 1320 of 3333 is done.\n",
      "Epoch 1330 of 3333 is done.\n",
      "Epoch 1340 of 3333 is done.\n",
      "Epoch 1350 of 3333 is done.\n",
      "Epoch 1360 of 3333 is done.\n",
      "Epoch 1370 of 3333 is done.\n",
      "Epoch 1380 of 3333 is done.\n",
      "Epoch 1390 of 3333 is done.\n",
      "Epoch 1400 of 3333 is done.\n",
      "Epoch 1410 of 3333 is done.\n",
      "Epoch 1420 of 3333 is done.\n",
      "Epoch 1430 of 3333 is done.\n",
      "Epoch 1440 of 3333 is done.\n",
      "Epoch 1450 of 3333 is done.\n",
      "Epoch 1460 of 3333 is done.\n",
      "Epoch 1470 of 3333 is done.\n",
      "Epoch 1480 of 3333 is done.\n",
      "Epoch 1490 of 3333 is done.\n",
      "Epoch 1500 of 3333 is done.\n",
      "Epoch 1510 of 3333 is done.\n",
      "Epoch 1520 of 3333 is done.\n",
      "Epoch 1530 of 3333 is done.\n",
      "Epoch 1540 of 3333 is done.\n",
      "Epoch 1550 of 3333 is done.\n",
      "Epoch 1560 of 3333 is done.\n",
      "Epoch 1570 of 3333 is done.\n",
      "Epoch 1580 of 3333 is done.\n",
      "Epoch 1590 of 3333 is done.\n",
      "Epoch 1600 of 3333 is done.\n",
      "Epoch 1610 of 3333 is done.\n",
      "Epoch 1620 of 3333 is done.\n",
      "Epoch 1630 of 3333 is done.\n",
      "Epoch 1640 of 3333 is done.\n",
      "Epoch 1650 of 3333 is done.\n",
      "Epoch 1660 of 3333 is done.\n",
      "Epoch 1670 of 3333 is done.\n",
      "Epoch 1680 of 3333 is done.\n",
      "Epoch 1690 of 3333 is done.\n",
      "Epoch 1700 of 3333 is done.\n",
      "Epoch 1710 of 3333 is done.\n",
      "Epoch 1720 of 3333 is done.\n",
      "Epoch 1730 of 3333 is done.\n",
      "Epoch 1740 of 3333 is done.\n",
      "Epoch 1750 of 3333 is done.\n",
      "Epoch 1760 of 3333 is done.\n",
      "Epoch 1770 of 3333 is done.\n",
      "Epoch 1780 of 3333 is done.\n",
      "Epoch 1790 of 3333 is done.\n",
      "Epoch 1800 of 3333 is done.\n",
      "Epoch 1810 of 3333 is done.\n",
      "Epoch 1820 of 3333 is done.\n",
      "Epoch 1830 of 3333 is done.\n",
      "Epoch 1840 of 3333 is done.\n",
      "Epoch 1850 of 3333 is done.\n",
      "Epoch 1860 of 3333 is done.\n",
      "Epoch 1870 of 3333 is done.\n",
      "Epoch 1880 of 3333 is done.\n",
      "Epoch 1890 of 3333 is done.\n",
      "Epoch 1900 of 3333 is done.\n",
      "Epoch 1910 of 3333 is done.\n",
      "Epoch 1920 of 3333 is done.\n",
      "Epoch 1930 of 3333 is done.\n",
      "Epoch 1940 of 3333 is done.\n",
      "Epoch 1950 of 3333 is done.\n",
      "Epoch 1960 of 3333 is done.\n",
      "Epoch 1970 of 3333 is done.\n",
      "Epoch 1980 of 3333 is done.\n",
      "Epoch 1990 of 3333 is done.\n",
      "Epoch 2000 of 3333 is done.\n",
      "Epoch 2010 of 3333 is done.\n",
      "Epoch 2020 of 3333 is done.\n",
      "Epoch 2030 of 3333 is done.\n",
      "Epoch 2040 of 3333 is done.\n",
      "Epoch 2050 of 3333 is done.\n",
      "Epoch 2060 of 3333 is done.\n",
      "Epoch 2070 of 3333 is done.\n",
      "Epoch 2080 of 3333 is done.\n",
      "Epoch 2090 of 3333 is done.\n",
      "Epoch 2100 of 3333 is done.\n",
      "Epoch 2110 of 3333 is done.\n",
      "Epoch 2120 of 3333 is done.\n",
      "Epoch 2130 of 3333 is done.\n",
      "Epoch 2140 of 3333 is done.\n",
      "Epoch 2150 of 3333 is done.\n",
      "Epoch 2160 of 3333 is done.\n",
      "Epoch 2170 of 3333 is done.\n",
      "Epoch 2180 of 3333 is done.\n",
      "Epoch 2190 of 3333 is done.\n",
      "Epoch 2200 of 3333 is done.\n",
      "Epoch 2210 of 3333 is done.\n",
      "Epoch 2220 of 3333 is done.\n",
      "Epoch 2230 of 3333 is done.\n",
      "Epoch 2240 of 3333 is done.\n",
      "Epoch 2250 of 3333 is done.\n",
      "Epoch 2260 of 3333 is done.\n",
      "Epoch 2270 of 3333 is done.\n",
      "Epoch 2280 of 3333 is done.\n",
      "Epoch 2290 of 3333 is done.\n",
      "Epoch 2300 of 3333 is done.\n",
      "Epoch 2310 of 3333 is done.\n",
      "Epoch 2320 of 3333 is done.\n",
      "Epoch 2330 of 3333 is done.\n",
      "Epoch 2340 of 3333 is done.\n",
      "Epoch 2350 of 3333 is done.\n",
      "Epoch 2360 of 3333 is done.\n",
      "Epoch 2370 of 3333 is done.\n",
      "Epoch 2380 of 3333 is done.\n",
      "Epoch 2390 of 3333 is done.\n",
      "Epoch 2400 of 3333 is done.\n",
      "Epoch 2410 of 3333 is done.\n",
      "Epoch 2420 of 3333 is done.\n",
      "Epoch 2430 of 3333 is done.\n",
      "Epoch 2440 of 3333 is done.\n",
      "Epoch 2450 of 3333 is done.\n",
      "Epoch 2460 of 3333 is done.\n",
      "Epoch 2470 of 3333 is done.\n",
      "Epoch 2480 of 3333 is done.\n",
      "Epoch 2490 of 3333 is done.\n",
      "Epoch 2500 of 3333 is done.\n",
      "Epoch 2510 of 3333 is done.\n",
      "Epoch 2520 of 3333 is done.\n",
      "Epoch 2530 of 3333 is done.\n",
      "Epoch 2540 of 3333 is done.\n",
      "Epoch 2550 of 3333 is done.\n",
      "Epoch 2560 of 3333 is done.\n",
      "Epoch 2570 of 3333 is done.\n",
      "Epoch 2580 of 3333 is done.\n",
      "Epoch 2590 of 3333 is done.\n",
      "Epoch 2600 of 3333 is done.\n",
      "Epoch 2610 of 3333 is done.\n",
      "Epoch 2620 of 3333 is done.\n",
      "Epoch 2630 of 3333 is done.\n",
      "Epoch 2640 of 3333 is done.\n",
      "Epoch 2650 of 3333 is done.\n",
      "Epoch 2660 of 3333 is done.\n",
      "Epoch 2670 of 3333 is done.\n",
      "Epoch 2680 of 3333 is done.\n",
      "Epoch 2690 of 3333 is done.\n",
      "Epoch 2700 of 3333 is done.\n",
      "Epoch 2710 of 3333 is done.\n",
      "Epoch 2720 of 3333 is done.\n",
      "Epoch 2730 of 3333 is done.\n",
      "Epoch 2740 of 3333 is done.\n",
      "Epoch 2750 of 3333 is done.\n",
      "Epoch 2760 of 3333 is done.\n",
      "Epoch 2770 of 3333 is done.\n",
      "Epoch 2780 of 3333 is done.\n",
      "Epoch 2790 of 3333 is done.\n",
      "Epoch 2800 of 3333 is done.\n",
      "Epoch 2810 of 3333 is done.\n",
      "Epoch 2820 of 3333 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2830 of 3333 is done.\n",
      "Epoch 2840 of 3333 is done.\n",
      "Epoch 2850 of 3333 is done.\n",
      "Epoch 2860 of 3333 is done.\n",
      "Epoch 2870 of 3333 is done.\n",
      "Epoch 2880 of 3333 is done.\n",
      "Epoch 2890 of 3333 is done.\n",
      "Epoch 2900 of 3333 is done.\n",
      "Epoch 2910 of 3333 is done.\n",
      "Epoch 2920 of 3333 is done.\n",
      "Epoch 2930 of 3333 is done.\n",
      "Epoch 2940 of 3333 is done.\n",
      "Epoch 2950 of 3333 is done.\n",
      "Epoch 2960 of 3333 is done.\n",
      "Epoch 2970 of 3333 is done.\n",
      "Epoch 2980 of 3333 is done.\n",
      "Epoch 2990 of 3333 is done.\n",
      "Epoch 3000 of 3333 is done.\n",
      "Epoch 3010 of 3333 is done.\n",
      "Epoch 3020 of 3333 is done.\n",
      "Epoch 3030 of 3333 is done.\n",
      "Epoch 3040 of 3333 is done.\n",
      "Epoch 3050 of 3333 is done.\n",
      "Epoch 3060 of 3333 is done.\n",
      "Epoch 3070 of 3333 is done.\n",
      "Epoch 3080 of 3333 is done.\n",
      "Epoch 3090 of 3333 is done.\n",
      "Epoch 3100 of 3333 is done.\n",
      "Epoch 3110 of 3333 is done.\n",
      "Epoch 3120 of 3333 is done.\n",
      "Epoch 3130 of 3333 is done.\n",
      "Epoch 3140 of 3333 is done.\n",
      "Epoch 3150 of 3333 is done.\n",
      "Epoch 3160 of 3333 is done.\n",
      "Epoch 3170 of 3333 is done.\n",
      "Epoch 3180 of 3333 is done.\n",
      "Epoch 3190 of 3333 is done.\n",
      "Epoch 3200 of 3333 is done.\n",
      "Epoch 3210 of 3333 is done.\n",
      "Epoch 3220 of 3333 is done.\n",
      "Epoch 3230 of 3333 is done.\n",
      "Epoch 3240 of 3333 is done.\n",
      "Epoch 3250 of 3333 is done.\n",
      "Epoch 3260 of 3333 is done.\n",
      "Epoch 3270 of 3333 is done.\n",
      "Epoch 3280 of 3333 is done.\n",
      "Epoch 3290 of 3333 is done.\n",
      "Epoch 3300 of 3333 is done.\n",
      "Epoch 3310 of 3333 is done.\n",
      "Epoch 3320 of 3333 is done.\n",
      "Epoch 3330 of 3333 is done.\n"
     ]
    }
   ],
   "source": [
    "top_3_models, top_3_histories, indices = train_all_models(top = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 10, 9]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "1024\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(possible_batch_sizes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found in our case the top 3 performing models had a 16, 795 or 800 neurons. Since 795 and 800 are quite similar, we will only compare 16 and 800 in the cross-optimization.\n",
    "\n",
    "We also found the larger the batch_size (for 500 Epochs) the better are the results. the best results were achieved with a batch_size of 2048 and 1024 (for 500 Epochs with only 1 fully connected layer as well as LSTM + 2 dense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
