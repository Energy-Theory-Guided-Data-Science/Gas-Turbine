{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "### Description\n",
    "This file is for the implementation of the knowledge into the loss function. We therefor use a loss function consisting of two tasks. First we use state-of-the-art ML loss function (ADAM) for the prediction of the output. Secondly, we use a new designed loss function using ReLU to limit the boundaries of the differences. The same is proposed by [1].\n",
    "\n",
    "[1]: Incorporating Prior Domain Knowledge into Deep Neural Networks, Muralidhar et al, 2018 - https://par.nsf.gov/servlets/purl/10086794\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimaries\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade files\n",
    "import Global_Functions as gf\n",
    "import Neuronal_Networks as nn\n",
    "# Processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "timestr = time.strftime(\"%Y-%m-%d_%H-%M_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_FOLDER = '../Data/Preped_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_1 = gf.open_CSV_file('experiment_1_short.csv', OPEN_FOLDER)\n",
    "ex_4 = gf.open_CSV_file('experiment_4_short.csv', OPEN_FOLDER)\n",
    "ex_9 = gf.open_CSV_file('experiment_9_short.csv', OPEN_FOLDER)\n",
    "ex_20 = gf.open_CSV_file('experiment_20_short.csv', OPEN_FOLDER)\n",
    "ex_21 = gf.open_CSV_file('experiment_21_short.csv', OPEN_FOLDER)\n",
    "ex_22 = gf.open_CSV_file('experiment_22_short.csv', OPEN_FOLDER)\n",
    "ex_23 = gf.open_CSV_file('experiment_23_short.csv', OPEN_FOLDER)\n",
    "ex_24 = gf.open_CSV_file('experiment_24_short.csv', OPEN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [ex_1, ex_4, ex_9, ex_20, ex_21, ex_22, ex_23, ex_24]\n",
    "names = ['1', '4', '9', '20', '21','22', '23', '24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_SYNTHETIC = 'C:/Users/FlorianLeiser/Documents/Masterarbeit/Data/Synthetic_Data/Without_Noise/Sample_Ratio_1/quadratic_12_34_linear_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = gf.load_synthetic(OPEN_SYNTHETIC, length = 50)\n",
    "names = [str(x+1) for x in range(len(experiments)-1)]\n",
    "names.append(\"hand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Parameters and Folder for Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEUR = 128\n",
    "EPOCH = 500\n",
    "LAG = 60\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"30\"\n",
    "val = \"10\"\n",
    "\n",
    "train_exs = experiments[:30]\n",
    "ex_train = gf.use_multiple_experiments(train_exs)\n",
    "ex_val = gf.use_multiple_experiments(experiments[30:40])\n",
    "ex_test = gf.use_multiple_experiments(experiments[40:50])\n",
    "# ex_train = ex_20\n",
    "# ex_val = ex_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of directory ../Images/Loss_function/2021-05-18_16-58_training_30 val_10 128_neurons__500_epochs__lag_60/ successful.\n"
     ]
    }
   ],
   "source": [
    "#saving folder for images\n",
    "image_path = \"../Images/Loss_function/\" + timestr\n",
    "specs = \"training_{0} val_{1} {2}_neurons__{3}_epochs__lag_{4}/\" \n",
    "image_folder = image_path + specs.format(train, val, NEUR, EPOCH, LAG)\n",
    "\n",
    "gf.check_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of directory ../Models/Loss_function/2021-05-18_16-58_training_30 val_10 128_neurons__500_epochs__lag_60/ successful.\n"
     ]
    }
   ],
   "source": [
    "#saving folder for models\n",
    "model_path = \"../Models/Loss_function/\" + timestr\n",
    "specs = \"training_{0} val_{1} {2}_neurons__{3}_epochs__lag_{4}/\" \n",
    "model_folder = model_path + specs.format(train, val, NEUR, EPOCH, LAG)\n",
    "\n",
    "gf.check_folder(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(prm_diff, prm_tgds, diff_value):\n",
    "    def loss_function_diff(y_true, y_predicted):\n",
    "        known_diff_trans = np.full(len(y_predicted), diff_value)\n",
    "        known_tensor_trans = tf.convert_to_tensor(known_diff_trans, dtype = 'float32')\n",
    "        known_diff_static = np.full(len(y_predicted), 0)\n",
    "        known_tensor_static = tf.convert_to_tensor(known_diff_static, dtype = 'float32')\n",
    "        \n",
    "        criterion = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        loss1 = criterion(y_true[:,0], y_predicted[:,0])\n",
    "        diff_loss = criterion(y_true[:,0], y_predicted[:,0])\n",
    "        tgds_loss_trans = criterion(abs(y_predicted[:,0][:,1]), known_tensor_trans)\n",
    "        tgds_loss_static = criterion(abs(y_predicted[:,0][:,1]), known_tensor_static)\n",
    "        tgds_loss = tf.math.minimum(tgds_loss_static, tgds_loss_trans)\n",
    "        \n",
    "        loss = loss1 + prm_diff * diff_loss + prm_tgds * tgds_loss\n",
    "        return loss\n",
    "    return loss_function_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, history, scaler_train, X_train, y_train, _, X_val, y_val = nn.train_model(ex_train, ex_val, save_folder = model_folder,\n",
    "#                                                                                   difference_chosen = \"predict\", loss_function = loss_func(1, 0.1, 1),\n",
    "#                                                                                  lag_chosen = LAG, nmb_epochs = EPOCH, neurons_chosen=NEUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "Try to fit appropriate hyperparameters for the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_diff = [0]\n",
    "parameters_tgds = [0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_opt(parameters_diff, parameters_tgds, image_folder):\n",
    "    multi_index = pd.MultiIndex.from_product([parameters_diff, parameters_tgds], names = ['diff', 'tgds'])\n",
    "    results = pd.DataFrame(index = multi_index, columns = ['rmse', 'r2', 'mae', 'maxae', 'rmse_diff', 'r2_diff', 'mae_diff', 'maxae_diff'])\n",
    "    limit = max(ex_train['el_power'].diff(periods = LAG)[LAG:])\n",
    "    for p in parameters_diff:\n",
    "        for p_t in parameters_tgds:\n",
    "            rms, r2, mae, maxae = [], [], [], []\n",
    "            rms_diff, r2_diff, mae_diff, maxae_diff = [], [], [], []\n",
    "            IMAGE_FOLDER = image_folder + \"Diff_weight_{}_TGDS_weight_{}/\".format(p, p_t)\n",
    "            gf.check_folder(IMAGE_FOLDER)\n",
    "            model, history, scaler_train, X_train, y_train, _, X_val, y_val = nn.train_model(ex_train, ex_val, batch_size = BATCH_SIZE,\n",
    "                                                                                save_folder = model_folder + \"Diff_weight_{}_TGDS_weight_{}/\".format(p, p_t),\n",
    "                                                                                difference_chosen = \"predict\", loss_function = loss_func(p, p_t, limit),\n",
    "                                                                                lag_chosen = LAG, nmb_epochs = EPOCH, neurons_chosen=NEUR)\n",
    "            for i in range(len(experiments)):\n",
    "                scaler, X, y, preds_scaled, preds = nn.predictions(experiments[i], model, difference_chosen = \"predict\", lag_chosen = LAG, batch_size = BATCH_SIZE)\n",
    "                \n",
    "                results_ex = gf.measure_difference(y, preds, should_print = False)\n",
    "                \n",
    "                gf.create_prediction_plot(experiments[i]['el_power'], preds, IMAGE_FOLDER,\n",
    "                              title = 'Predictions using loss function ',\n",
    "                             specs = 'on ex_{0} with model trained on {1}'.format(names[i], train))\n",
    "                gf.create_prediction_plot(y, preds_scaled, IMAGE_FOLDER,\n",
    "                              title = 'Predictions of Differences using loss function ',\n",
    "                             specs = 'differences_on ex_{0} with model trained on {1}'.format(names[i], train))\n",
    "                \n",
    "                rms.append(results_ex['RMSE'][0])\n",
    "                r2.append(results_ex['R2'][0])\n",
    "                mae.append(results_ex['MAE'][0])\n",
    "                maxae.append(results_ex['MaxAE'][0])\n",
    "                \n",
    "            results.loc[(p, p_t), 'rmse'] = rms\n",
    "            results.loc[(p, p_t), 'r2'] = r2\n",
    "            results.loc[(p, p_t), 'mae'] = mae\n",
    "            results.loc[(p, p_t), 'maxae'] = maxae\n",
    "            results.to_csv(image_folder + \"results.csv\", sep = \"|\", encoding = 'utf-8')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of directory ../Images/Loss_function/2021-05-18_16-58_training_30 val_10 128_neurons__500_epochs__lag_60/Diff_weight_0_TGDS_weight_0.01/ successful.\n",
      "Creation of directory ../Models/Loss_function/2021-05-18_16-58_training_30 val_10 128_neurons__500_epochs__lag_60/Diff_weight_0_TGDS_weight_0.01/ successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FlorianLeiser\\Documents\\Masterarbeit\\Code\\Data_Processing.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['diff'] = diffs\n",
      "C:\\Users\\FlorianLeiser\\Documents\\Masterarbeit\\Code\\Data_Processing.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['diff'] = diffs\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_opt(parameters_diff, parameters_tgds, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
