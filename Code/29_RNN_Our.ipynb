{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version suitable to our case\n",
    "\n",
    "The problem in the implementation above is, that training and testing data uses the electric power. Obviously they provide good results. However, our task where we want to model the behavior depending on the input beforehand is not solved.\n",
    "\n",
    "For our task we need to implement a network where it takes the current and previous inputs to predict the electrical output. If useful, we can include the previous electrical oputput as well.\n",
    "\n",
    "For all the data we need to implement the difference, scale all and then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import Global_Functions as gf\n",
    "import matplotlib.pyplot as plt\n",
    "import Neuronal_Networks as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y-%m-%d_%H-%M_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_FOLDER = '../Data/Preped_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_1 = gf.open_CSV_file('experiment_1_short.csv', OPEN_FOLDER)\n",
    "ex_4 = gf.open_CSV_file('experiment_4_short.csv', OPEN_FOLDER)\n",
    "ex_9 = gf.open_CSV_file('experiment_9_short.csv', OPEN_FOLDER)\n",
    "ex_20 = gf.open_CSV_file('experiment_20_short.csv', OPEN_FOLDER)\n",
    "ex_21 = gf.open_CSV_file('experiment_21_short.csv', OPEN_FOLDER)\n",
    "ex_22 = gf.open_CSV_file('experiment_22_short.csv', OPEN_FOLDER)\n",
    "ex_23 = gf.open_CSV_file('experiment_23_short.csv', OPEN_FOLDER)\n",
    "ex_24 = gf.open_CSV_file('experiment_24_short.csv', OPEN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"4\"\n",
    "val = \"21\"\n",
    "\n",
    "ex_train = ex_4\n",
    "ex_val = ex_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEUR = 128\n",
    "EPOCH = 100\n",
    "LAG = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists.\n",
      "Folder already exists.\n",
      "Creation of directory ../Images/RNN/2021-03-19_09-36_training_4 val_21 128_neurons__100_epochs__lag_60/ successful.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"../Images/\"\n",
    "image_subfolder = image_path + \"RNN/\"\n",
    "specs = \"training_{0} val_{1} {2}_neurons__{3}_epochs__lag_{4}\" \n",
    "image_folder = image_subfolder + timestr + specs.format(train, val, NEUR, EPOCH, LAG) + \"/\"\n",
    "\n",
    "gf.check_folder(image_path)\n",
    "gf.check_folder(image_subfolder)\n",
    "gf.check_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kit_orange = gf.get_color('orange')\n",
    "kit_green = gf.get_color('green')\n",
    "kit_blue = gf.get_color('blue')\n",
    "kit_cyan = gf.get_color('cyan')\n",
    "kit_red = gf.get_color('red')\n",
    "kit_lightgreen = gf.get_color('lightgreen')\n",
    "kit_grey = gf.get_color('grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make time series to supervised problem\n",
    "\n",
    "We need to restructure the data to have a supervised learning problem. Within we need to get the necessary inputs and necessary outputs as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def timeseries_to_supervised(data, lag = 10):\n",
    "#     df = pd.DataFrame(data)\n",
    "#     columns = [df.shift(i) for i in range(1, lag +1)]\n",
    "#     df_delay = pd.concat(columns, axis = 1)\n",
    "#     df = pd.concat([df, df_delay], axis = 1)\n",
    "#     df.fillna(0, inplace = True)\n",
    "#     df.columns = [str(\"delay_\" + str(i)) for i in range(0, lag +1)]\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def difference(data, lag = 10):\n",
    "#     diff = list()\n",
    "#     for i in range(lag, len(data)):\n",
    "#         value = data[i] - data[i - lag]\n",
    "#         diff.append(value)\n",
    "#     return pd.Series(diff, name = data.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def invert_difference(data, yhat, index = 0):\n",
    "#     return yhat + data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale(data_series, scaler = None):\n",
    "#     data = data_series.values\n",
    "#     data = data.reshape(-1, 1)\n",
    "#     if scaler is None:\n",
    "#         scaler = MinMaxScaler(feature_range = (-1,1), )\n",
    "#         scaler = scaler.fit(data)\n",
    "#     data_scaled = scaler.transform(data)\n",
    "#     return data_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def invert_scale(scaler, value):\n",
    "#     return scaler.inverse_transform(value.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_lstm(X_train, y_train, X_val, y_val, batch_size, nb_epochs, neurons): \n",
    "#     model = Sequential()\n",
    "#     model.add(layers.LSTM(neurons, batch_input_shape = (batch_size, X_train.shape[1], X_train.shape[2]), stateful = True))\n",
    "#     model.add(layers.Dense(1))\n",
    "#     model.compile(loss = 'mean_squared_error', optimizer = 'adam', )\n",
    "#     for i in range(nb_epochs):\n",
    "#         model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 1, batch_size = batch_size, verbose = 1, shuffle = False)\n",
    "#         model.reset_states()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second try\n",
    "\n",
    "We do all from scratch building our own data frame and using scaling and preparation of data according to our understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(experiment_train, experiment_val, lag_input = 1, lag_output = 1, batch_size = 1, neurons = 8, nb_epochs = 10):\n",
    "    scaler_train, X_train, y_train = nn.prepare_data(experiment_train, lag_input, lag_output, all_lags = False)\n",
    "    scaler_val, X_val, y_val = nn.prepare_data(experiment_val, lag_input, lag_output, all_lags = False)\n",
    "    \n",
    "    model = nn.fit_lstm(X_train, y_train, X_val, y_val, batch_size, nb_epochs, neurons)\n",
    "    \n",
    "    return model, scaler_train, X_train, y_train, scaler_val, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0057 - val_loss: 1.3975\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0041 - val_loss: 1.5266\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0095 - val_loss: 1.3508\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0034 - val_loss: 1.7957\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0028 - val_loss: 3.1989\n",
      "9782/9795 [============================>.] - ETA: 0s - loss: 0.0035WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0035 - val_loss: 2.7570\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0035 - val_loss: 2.4775\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0030 - val_loss: 2.2489\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0036 - val_loss: 2.0568\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0055 - val_loss: 0.8172\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0033 - val_loss: 0.1409\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0034 - val_loss: 0.1390\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0033 - val_loss: 0.0540\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0036 - val_loss: 0.0380\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0036 - val_loss: 0.0361\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0036 - val_loss: 0.2427\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0029 - val_loss: 0.0415\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0035 - val_loss: 0.0506\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0041 - val_loss: 0.1537\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0037 - val_loss: 0.0818\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0035 - val_loss: 0.0623\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0035 - val_loss: 0.0735\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0033 - val_loss: 0.0489\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0031 - val_loss: 0.0416\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0036 - val_loss: 0.0452\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0029 - val_loss: 0.0604\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0031 - val_loss: 0.0796\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0028 - val_loss: 0.0660\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0026 - val_loss: 0.0738\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0027 - val_loss: 0.0859\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0027 - val_loss: 0.0893\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0030 - val_loss: 0.1391\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0030 - val_loss: 0.1070\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0029 - val_loss: 0.0775\n",
      "9795/9795 [==============================] - 21s 2ms/step - loss: 0.0028 - val_loss: 0.1172\n",
      "9795/9795 [==============================] - 17s 2ms/step - loss: 0.0033 - val_loss: 0.0723\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0032 - val_loss: 0.1187\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0033 - val_loss: 0.0912\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0034 - val_loss: 0.1110\n",
      "9795/9795 [==============================] - 17s 2ms/step - loss: 0.0034 - val_loss: 0.0850\n",
      "9795/9795 [==============================] - 17s 2ms/step - loss: 0.0033 - val_loss: 0.1016\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0033 - val_loss: 0.1101\n",
      "9795/9795 [==============================] - 17s 2ms/step - loss: 0.0032 - val_loss: 0.0937\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0032 - val_loss: 0.1119\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0034 - val_loss: 0.1175\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0035 - val_loss: 0.1133\n",
      "9795/9795 [==============================] - 16s 2ms/step - loss: 0.0037 - val_loss: 0.0850\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0040 - val_loss: 0.1008\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0043 - val_loss: 0.1284\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0045 - val_loss: 0.2311\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0084 - val_loss: 0.4780\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0076 - val_loss: 0.2091\n",
      "9795/9795 [==============================] - 20s 2ms/step - loss: 0.0047 - val_loss: 0.2665\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0045 - val_loss: 0.2083\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0042 - val_loss: 0.1571\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0039 - val_loss: 0.1069\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0038 - val_loss: 0.1054\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0036 - val_loss: 0.1020\n",
      "9795/9795 [==============================] - 19s 2ms/step - loss: 0.0038 - val_loss: 0.1418\n",
      "9770/9795 [============================>.] - ETA: 0s - loss: 0.0047WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0013s). Check your callbacks.\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0047 - val_loss: 0.1606\n",
      "9795/9795 [==============================] - 18s 2ms/step - loss: 0.0123 - val_loss: 0.2759\n",
      "9763/9795 [============================>.] - ETA: 0s - loss: 0.0062"
     ]
    }
   ],
   "source": [
    "model, scaler, X_train, y_train, _, X_val, y_val = train_model(ex_train, ex_val, lag_input=LAG, lag_output = 1, batch_size=1, neurons=NEUR, nb_epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(experiment, model, batch_size = 1, specs = \"\"):\n",
    "    scaler, X, y = nn.prepare_data(experiment, lag_input=LAG, all_lags = False)\n",
    "    \n",
    "    preds_scaled = model.predict(X, batch_size = batch_size)\n",
    "    preds = scaler[1].inverse_transform(preds_scaled)\n",
    "    \n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    plt.plot(experiment['el_power'], color = gf.get_color(\"grey\"), label = \"True\")\n",
    "    plt.plot(preds, color = gf.get_color(\"green\"), label = \"Predictions\")\n",
    "    plt.ylabel('Electric power in [W]')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylim([0, 4000])\n",
    "    plt.legend()\n",
    "    plt.title('Comparison predictions to true values' + specs, fontsize = 14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(image_folder + specs + \"predictions.png\")\n",
    "    fig.savefig(image_folder + specs + \"predictions.svg\")\n",
    "    \n",
    "    return scaler, X, y, preds_scaled, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler_1, X_1, y_1, preds_scaled_1, preds_1 = predictions(ex_1, model, specs = \" on ex_1 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_4, X_4, y_4, preds_scaled_4, preds_4 = predictions(ex_4, model, specs = \" on ex_4 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler_9, X_9, y_9, preds_scaled_9, preds_9 = predictions(ex_9, model, specs = \" on ex_9 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_20, X_20, y_20, preds_scaled_20, preds_20 = predictions(ex_20, model, specs = \" on ex_20 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_21, X_21, y_21, preds_scaled_21, preds_21 = predictions(ex_21, model, specs = \" on ex_21 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_22, X_22, y_22, preds_scaled_22, preds_22 = predictions(ex_22, model, specs = \" on ex_22 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_23, X_23, y_23, preds_scaled_23, preds_23 = predictions(ex_23, model, specs = \" on ex_23 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_24, X_24, y_24, preds_scaled_24, preds_24 = predictions(ex_24, model, specs = \" on ex_24 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
