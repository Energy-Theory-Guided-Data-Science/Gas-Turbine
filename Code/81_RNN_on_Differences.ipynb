{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import Global_Functions as gf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Neuronal_Networks as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y-%m-%d_%H-%M_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_FOLDER = '../Data/Preped_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_1 = gf.open_CSV_file('experiment_1_short.csv', OPEN_FOLDER)\n",
    "ex_4 = gf.open_CSV_file('experiment_4_short.csv', OPEN_FOLDER)\n",
    "ex_9 = gf.open_CSV_file('experiment_9_short.csv', OPEN_FOLDER)\n",
    "ex_20 = gf.open_CSV_file('experiment_20_short.csv', OPEN_FOLDER)\n",
    "ex_21 = gf.open_CSV_file('experiment_21_short.csv', OPEN_FOLDER)\n",
    "ex_22 = gf.open_CSV_file('experiment_22_short.csv', OPEN_FOLDER)\n",
    "ex_23 = gf.open_CSV_file('experiment_23_short.csv', OPEN_FOLDER)\n",
    "ex_24 = gf.open_CSV_file('experiment_24_short.csv', OPEN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"20\"\n",
    "val = \"21\"\n",
    "\n",
    "ex_train = ex_20\n",
    "ex_val = ex_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEUR = 128\n",
    "EPOCH = 100\n",
    "LAG = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists.\n",
      "Folder already exists.\n",
      "Creation of directory ../Images/Differences/2021-03-19_09-26_training_20 val_21 128_neurons__100_epochs__lag_60/ successful.\n"
     ]
    }
   ],
   "source": [
    "image_path = \"../Images/\"\n",
    "image_subfolder = image_path + \"Differences/\"\n",
    "specs = \"training_{0} val_{1} {2}_neurons__{3}_epochs__lag_{4}\" \n",
    "image_folder = image_subfolder + timestr + specs.format(train, val, NEUR, EPOCH, LAG) + \"/\"\n",
    "\n",
    "gf.check_folder(image_path)\n",
    "gf.check_folder(image_subfolder)\n",
    "gf.check_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(experiment_train, experiment_validation, lag_input=1, lag_output=1, batch_size = 1, nmb_epochs = 20, neurons = 64):\n",
    "    scaler_train, X_train, y_train = nn.prepare_data(experiment_train, lag_input = lag_input, all_lags = False, differences = 'only', hybrid = False)\n",
    "    scaler_val, X_val, y_val = nn.prepare_data(experiment_validation, lag_input = lag_input, all_lags = False,  differences = 'only', hybrid = False)\n",
    "    \n",
    "    model = nn.fit_lstm(X_train, y_train, X_val, y_val, 1, nb_epochs = nmb_epochs, neurons = neurons)\n",
    "    \n",
    "    return model, scaler_train, X_train, y_train, scaler_val, X_val, y_val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0447 - val_loss: 0.6023\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0189 - val_loss: 0.6153\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0185 - val_loss: 0.6044\n",
      "6495/6495 [==============================] - 16s 3ms/step - loss: 0.0166 - val_loss: 0.5168\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0144 - val_loss: 0.6326\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0118 - val_loss: 0.8967\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0129 - val_loss: 0.6717\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0140 - val_loss: 0.6097\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0126 - val_loss: 1.2455\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0210 - val_loss: 0.7334\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0193 - val_loss: 0.6981\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0196 - val_loss: 1.2079\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0238 - val_loss: 0.9333\n",
      "6477/6495 [============================>.] - ETA: 0s - loss: 0.0197WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0197 - val_loss: 0.9175\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0232 - val_loss: 0.6851\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0174 - val_loss: 0.7491\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0161 - val_loss: 0.6769\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0119 - val_loss: 0.9125\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0141 - val_loss: 1.0140\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0186 - val_loss: 0.8612\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0203 - val_loss: 1.1765\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0199 - val_loss: 0.9055\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0213 - val_loss: 1.0656\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0211 - val_loss: 1.0480\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0243 - val_loss: 1.6377\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0251 - val_loss: 1.1649\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0202 - val_loss: 0.8733\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0146 - val_loss: 1.0272\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0211 - val_loss: 1.1419\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0165 - val_loss: 1.2378\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0258 - val_loss: 1.1431\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0282 - val_loss: 1.6044\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0233 - val_loss: 0.7856\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0204 - val_loss: 1.2764\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0217 - val_loss: 1.1223\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0143 - val_loss: 0.5197\n",
      "6495/6495 [==============================] - 14s 2ms/step - loss: 0.0207 - val_loss: 1.2305\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0305 - val_loss: 1.3366\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0306 - val_loss: 1.0146\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0193 - val_loss: 1.1487\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0219 - val_loss: 1.0337\n",
      "6481/6495 [============================>.] - ETA: 0s - loss: 0.0385WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0384 - val_loss: 2.8302\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0437 - val_loss: 1.5847\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0440 - val_loss: 2.4682\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0447 - val_loss: 1.7435\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0277 - val_loss: 1.7555\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0368 - val_loss: 1.0277\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0358 - val_loss: 1.7590\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0439 - val_loss: 1.5626\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0354 - val_loss: 1.3440\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0378 - val_loss: 1.2545\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0333 - val_loss: 2.0973\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0386 - val_loss: 1.1931\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0394 - val_loss: 1.0960\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0232 - val_loss: 0.7342\n",
      "6495/6495 [==============================] - 16s 2ms/step - loss: 0.0267 - val_loss: 1.2360\n",
      "6476/6495 [============================>.] - ETA: 0s - loss: 0.0319WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0319 - val_loss: 2.1811\n",
      "6495/6495 [==============================] - 15s 2ms/step - loss: 0.0371 - val_loss: 1.7426\n",
      "6495/6495 [==============================] - 13s 2ms/step - loss: 0.0366 - val_loss: 1.0436\n",
      "6493/6495 [============================>.] - ETA: 0s - loss: 0.0445WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 12s 2ms/step - loss: 0.0445 - val_loss: 1.6657\n",
      "6495/6495 [==============================] - 10s 2ms/step - loss: 0.0466 - val_loss: 1.4253\n",
      "6466/6495 [============================>.] - ETA: 0s - loss: 0.0368WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 10s 2ms/step - loss: 0.0367 - val_loss: 1.4095\n",
      "6495/6495 [==============================] - 11s 2ms/step - loss: 0.0360 - val_loss: 0.8929\n",
      "6495/6495 [==============================] - 11s 2ms/step - loss: 0.0222 - val_loss: 1.2257\n",
      "6495/6495 [==============================] - 10s 2ms/step - loss: 0.0270 - val_loss: 1.4490\n",
      "6495/6495 [==============================] - 10s 2ms/step - loss: 0.0273 - val_loss: 0.6863\n",
      "6495/6495 [==============================] - 10s 2ms/step - loss: 0.0297 - val_loss: 1.3879\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0400 - val_loss: 0.8263\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0305 - val_loss: 1.7356\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0340 - val_loss: 2.5746\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0385 - val_loss: 1.1502\n",
      "6441/6495 [============================>.] - ETA: 0s - loss: 0.0296WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0296 - val_loss: 1.5494\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0307 - val_loss: 1.6780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0268 - val_loss: 1.1663\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0255 - val_loss: 1.9113\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0253 - val_loss: 1.1041\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0198 - val_loss: 1.4560\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0359 - val_loss: 1.7590\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0408 - val_loss: 1.3106\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0272 - val_loss: 1.0629\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0297 - val_loss: 2.1342\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0420 - val_loss: 1.4412\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0400 - val_loss: 1.3485\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0372 - val_loss: 1.1087\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0323 - val_loss: 1.0335\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0325 - val_loss: 1.6974\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0473 - val_loss: 1.8062\n",
      "6453/6495 [============================>.] - ETA: 0s - loss: 0.0335WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0334 - val_loss: 1.8897\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0318 - val_loss: 1.9982\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0387 - val_loss: 2.2481\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0338 - val_loss: 2.3355\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0313 - val_loss: 3.1015\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0547 - val_loss: 1.4784\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0501 - val_loss: 1.7484\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0367 - val_loss: 1.9013\n",
      "6495/6495 [==============================] - 8s 1ms/step - loss: 0.0470 - val_loss: 2.9339\n",
      "6495/6495 [==============================] - 8s 1ms/step - loss: 0.0485 - val_loss: 1.8678\n",
      "6446/6495 [============================>.] - ETA: 0s - loss: 0.0390WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6495/6495 [==============================] - 8s 1ms/step - loss: 0.0389 - val_loss: 2.1006\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0375 - val_loss: 2.1384\n",
      "6495/6495 [==============================] - 9s 1ms/step - loss: 0.0373 - val_loss: 2.2324\n"
     ]
    }
   ],
   "source": [
    "model, scaler_train, X_train, y_train, _, X_val, y_val = train_model(ex_train, ex_val, lag_input = LAG, nmb_epochs = EPOCH, neurons=NEUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(experiment, model, batch_size = 1, specs = \"\"):\n",
    "    scaler, X, y = nn.prepare_data(experiment_train, lag_input = lag_input, all_lags = False, differences = 'only', hybrid = False)\n",
    "    \n",
    "    preds_scaled = model.predict(X, batch_size = batch_size)\n",
    "    preds = scaler[1].inverse_transform(preds_scaled)\n",
    "    \n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    plt.plot(experiment['el_power'], color = gf.get_color(\"grey\"), label = \"True\")\n",
    "    plt.plot(preds, color = gf.get_color(\"green\"), label = \"Predictions\")\n",
    "    plt.ylabel('Electric power in [W]')\n",
    "    plt.xlabel('Time')\n",
    "    plt.legend()\n",
    "    plt.title('Comparison predictions to true values' + specs, fontsize = 14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(image_folder + specs + \"predictions.png\")\n",
    "    fig.savefig(image_folder + specs + \"predictions.svg\")\n",
    "    \n",
    "    return scaler, X, y, preds_scaled, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6a08a3d510c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaler_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_scaled_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" on ex_1 with model trained on \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-c42307763e82>\u001b[0m in \u001b[0;36mpredictions\u001b[1;34m(experiment, model, batch_size, specs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlag_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlag_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_lags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdifferences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'only'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhybrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpreds_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'experiment_train' is not defined"
     ]
    }
   ],
   "source": [
    "scaler_1, X_1, y_1, preds_scaled_1, preds_1 = predictions(ex_1, model, specs = \" on ex_1 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_4, X_4, y_4, preds_scaled_4, preds_4 = predictions(ex_4, model, specs = \" on ex_4 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler_9, X_9, y_9, preds_scaled_9, preds_9 = predictions(ex_9, model, specs = \" on ex_9 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_20, X_20, y_20, preds_scaled_20, preds_20 = predictions(ex_20, model, specs = \" on ex_20 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_21, X_21, y_21, preds_scaled_21, preds_21 = predictions(ex_21, model, specs = \" on ex_21 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_22, X_22, y_22, preds_scaled_22, preds_22 = predictions(ex_22, model, specs = \" on ex_22 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_23, X_23, y_23, preds_scaled_23, preds_23 = predictions(ex_23, model, specs = \" on ex_23 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_24, X_24, y_24, preds_scaled_24, preds_24 = predictions(ex_24, model, specs = \" on ex_24 with model trained on \" + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
